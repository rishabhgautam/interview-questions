# Feature Engineering, Experiments & Data Handling - Interview Notes

---

## 1. Alpha Experiments

- **Definition:** Early-stage, exploratory tests to quickly evaluate raw or engineered features.  
- **Goal:** Identify **signal presence** – does this feature correlate with the target or improve a simple model?  
- **Typical Approach:**  
  - Simple models: logistic regression, linear regression, single decision tree.  
  - Univariate statistical tests: correlation, mutual information, chi-square, ANOVA F-test.  
  - Visual inspection: scatter plots, histograms, boxplots to detect trends/outliers.  
- **Benefits:**  
  - Rapid iteration; can discard non-informative features early.  
  - Low computational cost compared to full-scale modeling.  
- **Example:** Testing whether `customer_age` or `last_purchase_amount` is predictive of churn using a small logistic regression model.

---

## 2. Beta Experiments

- **Definition:** Later-stage experiments after features have passed alpha checks; closer to real modeling conditions.  
- **Goal:** Validate performance using realistic datasets, splits, and model pipelines.  
- **Approach:**  
  - Cross-validation and hold-out sets for robust metric evaluation.  
  - Ablation studies: remove individual features/groups to see their contribution.  
  - Compare multiple candidate models/pipelines to pick the best configuration.  
- **Outputs:**  
  - Final feature set and model selection.  
  - Preparation for A/B testing, production deployment, or monitoring strategy.  
- **Example:** Testing whether adding `customer_engagement_score` improves a churn prediction pipeline in a 5-fold cross-validation setup.

---

## 3. Feature Selection Techniques

- **Filter Methods:**  
  - Fast, univariate approaches independent of model.  
  - Examples: Pearson correlation, Spearman rank, chi-square, mutual information, ANOVA F-test.  
  - Pros: Quick, scalable; Cons: ignore interactions between features.  

- **Wrapper Methods:**  
  - Iteratively add/remove features using a model to evaluate performance.  
  - Examples: Recursive Feature Elimination (RFE), forward/backward stepwise selection.  
  - Pros: Considers feature interactions; Cons: computationally expensive.  

- **Embedded Methods:**  
  - Feature selection occurs naturally within the model training.  
  - Examples: L1 regularization (lasso), tree-based feature importance, gradient boosting gain.  
  - Pros: Less expensive than wrapper methods, often interpretable.  

- **PCA vs Feature Importance:**  
  - PCA creates orthogonal components, reduces dimensionality, loses original feature interpretability.  
  - Importance methods rank original features by contribution, preserves interpretability.  

- **Practical Tip:** Use filter methods to narrow down candidates, embedded/wrapper for final refinement.

---

## 4. Missing Data Strategies

- **Simple Imputation:**  
  - Mean/median for numeric features.  
  - Mode or “missing” category for categorical features.  

- **Indicator Flags:**  
  - Add a binary feature marking missing values → allows model to detect patterns in missingness.  

- **Advanced Imputation:**  
  - KNN imputer, multivariate iterative imputation, model-based imputation (e.g., predicting missing values with another ML model).  

- **Algorithm-Specific Handling:**  
  - Some tree-based models handle missing values natively (splitting on missing as its own category).  

- **Consider Missingness Mechanism:**  
  - MCAR (Missing Completely at Random), MAR (Missing at Random), MNAR (Missing Not at Random) → influences imputation choice.

---

## 5. Standardization vs Normalization — When to Use Which

- **Standardization (Z-score):**  
  - Center to zero mean, scale to unit variance.  
  - Works best for algorithms assuming Gaussian-like features or using distance metrics (SVM, logistic regression, K-means, PCA).  

- **Normalization (Min–Max Scaling):**  
  - Scale features to [0, 1] or [-1, 1].  
  - Useful for neural networks, bounded inputs, or when features have different scales.  

- **Key Guidelines:**  
  - Fit scalers only on **training data**, apply same transformation to validation/test sets.  
  - Standardize before PCA, distance-based clustering, or gradient-based optimization.  
  - Normalize when feeding into neural networks or bounded activation functions.

---

## 6. Parquet Advantages & Compression Strategies

- **Columnar Storage:**  
  - Reads only required columns → reduces IO and speeds up queries.  

- **Schema Evolution:**  
  - Supports adding/removing columns or nested types without rewriting entire dataset.  

- **Compression & Encoding:**  
  - Combine **columnar layout + encoding**: dictionary encoding, run-length encoding, delta encoding.  
  - Use codecs: Snappy (fast), ZSTD (better compression), GZIP (high compression, slower).  
  - Reduces storage footprint, improves query performance, especially on large datasets.  

- **Best Practices:**  
  - Keep frequently queried columns separate (column pruning).  
  - Avoid wide tables with unnecessary columns.  
  - Use **predicate pushdown** with Parquet to filter rows early.  

- **Example:** Storing a 1B-row transaction table in Parquet with Snappy compression; queries on specific columns (e.g., `customer_id`, `transaction_amount`) return results 5–10x faster than CSV.

---

## 7. Additional Feature Engineering Tips

- **Interaction Features:** Combine two or more features (e.g., `age * income`) to capture non-linear relationships.  
- **Polynomial Features:** For linear models, create squared or cubic terms to model non-linearity.  
- **Binning / Bucketing:** Convert continuous features to categorical ranges (helps trees or logistic regression).  
- **Temporal Features:** Extract day-of-week, month, seasonality, rolling averages, lag features for time series.  
- **Text Features:** Token counts, TF-IDF, embeddings, sentiment scores.  
- **Categorical Features:** One-hot, target encoding, frequency encoding.  

- **Experiment Tracking:** Maintain feature experiments with metrics, versioning, and ablation results → ensures reproducibility and clarity for model iteration.

---

**Summary Mental Models:**  
- Alpha → quick, exploratory, univariate checks.  
- Beta → robust, model-level validation in realistic conditions.  
- Feature selection → filter first, embedded/wrapper later.  
- Missing values → simple → advanced → algorithm-specific.  
- Scaling → standardization for linear/distance models, normalization for neural nets.  
- Parquet → columnar + compression for analytics efficiency.  
- Always **track experiments**, evaluate contribution, and prioritize interpretability vs performance trade-offs.
