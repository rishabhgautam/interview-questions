# Feature Engineering, Experiments & Data Handling - Interview Notes

---

## 1. Alpha Experiments

- Alpha experiments are **early-stage, exploratory tests** to evaluate many raw or engineered features quickly.  
- Goal is to check **signal presence**: does this feature correlate with target or improve simple models?  
- Often done with simple models (logistic/linear, single tree, univariate tests) for fast iteration.  
- Helps shortlist promising features before investing in complex modeling or heavy engineering.

---

## 2. Beta Experiments

- Beta experiments are **later-stage, model-level tests** after a feature set or approach has passed alpha checks.  
- Goal is to validate performance in **near-real conditions**: realistic splits, baselines, ablation studies.  
- You compare candidate models, pipelines, or feature groups using robust metrics and cross-validation.  
- Outputs feed into final model selection, A/B testing plans, and deployment decisions.

---

## 3. Feature Selection Techniques

- **Filter methods:** correlations, mutual information, chi-square, ANOVA F-test; fast, univariate.  
- **Wrapper methods:** RFE (Recursive Feature Elimination), stepwise selection; iteratively add/remove features using a model.  
- **Embedded methods:** L1 regularization, tree-based feature importance, gradient boosting gain.  
- **PCA vs importance:** PCA creates new orthogonal components (good for compression), while importance methods keep original features and rank them for interpretability.

---

## 4. Missing Data Strategies

- **Simple imputation:** mean/median for numeric, mode/“missing” category for categorical.  
- **Indicator flags:** add a binary feature marking whether a value was missing.  
- **Advanced:** KNN/multivariate imputation, model-based imputation, or using algorithms that handle missing internally (e.g., some trees/GBDTs).  
- Choice depends on **missingness mechanism** (MCAR, MAR, MNAR) and model type.

---

## 5. Standardization vs Normalization — When to Use Which

- **Standardization:** transform to zero mean and unit variance; good for algorithms that assume Gaussian-like features or use distances with scale sensitivity (SVM, logistic regression, K-means, PCA).  
- **Normalization (min–max):** scale features to a fixed range (e.g., [0, 1]); useful when you care about **bounded inputs** or feeding into neural nets.  
- Use standardization for **most linear models and distance-based methods**; normalization for **neural networks or when features are naturally bounded**.  
- Never fit scalers on test data; always fit on train and apply to val/test.

---

## 6. Parquet Advantages & Compression Strategies

- **Parquet** is a columnar storage format: efficient reads of only needed columns, great for analytics workloads.  
- Supports **schema evolution**, nested types, and strong interoperability across big data tools (Spark, Hive, Presto, etc.).  
- Compression strategies: combine **columnar layout + encoding** (dictionary, run-length, delta encoding) with codecs (Snappy, ZSTD, GZIP) for high compression and fast IO.  
- Best practice: use **Snappy/ZSTD** for balance of speed and size, and prune unused columns at query time for maximum benefit.


