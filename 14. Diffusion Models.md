# Diffusion Models - Interview Notes

---

## 1. DDPM vs DDIM

**DDPM (Denoising Diffusion Probabilistic Models):**  
- Stochastic process: add Gaussian noise in many small steps (forward), then learn to reverse it (denoising).  
- Sampling is relatively **slow** because it requires many steps.

**DDIM (Denoising Diffusion Implicit Models):**  
- Deterministic variant with a **non-Markovian** reverse process.  
- Can use **fewer sampling steps** (accelerated sampling) while keeping similar quality.

---

## 2. Forward Diffusion & Denoising Process

- **Forward process:** Gradually add noise to data over T steps until it becomes nearly pure Gaussian noise.  
- The forward process is fixed and simple (no learned parameters).  
- **Reverse (denoising) process:** A neural network is trained to predict either the original data or the noise at each step.  
- At inference, you start from noise and iteratively denoise back to a realistic sample.

---

## 3. Loss Functions in Diffusion Models

- Typically, you train the model to **predict the noise** added at each step.  
- The standard loss is a **mean squared error (MSE)** between the true noise and the predicted noise.  
- Some variants predict the clean data or a combination (e.g., v-parameterization).  
- Different parameterizations can change stability and sample quality, but core idea is: “match the true diffusion process.”

---

## 4. Score Matching Loss (Score-based Diffusion)

- **Score** = gradient of log-density: ∇x log p(x), which points toward high-density regions.  
- Score-based models learn this score function at different noise levels.  
- The loss forces the model’s score to match the true data score (often via denoising score matching).  
- Sampling then follows a stochastic differential equation (SDE) using the learned score to move noise toward data.

---

## 5. Why “Stable” in Stable Diffusion?

- “Stable” refers partly to **Stable AI** (the company) and partly to **stable training/inference** in a latent space.  
- Stable Diffusion operates in a **compressed latent space** (via an autoencoder) rather than pixel space.  
- This makes training and inference more **efficient and numerically stable** for high-resolution images.  
- It enabled high-quality, fast, and relatively lightweight image generation.

---

## 6. High-Level Functioning vs Other Generative Models

- **Diffusion models:** Start from noise → iteratively denoise; typically great quality and diversity, but multi-step sampling.  
- **GANs:** Learn a generator vs discriminator in an adversarial setup; fast one-shot sampling, but training is unstable and prone to mode collapse.  
- **VAEs:** Encode to latent distribution and decode; smooth latent space, but samples can be blurrier.  
- Diffusion models trade slower sampling for **stable training and very high-fidelity outputs**.


